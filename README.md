# ğŸš€ Prophantom Johnnet AI 2.0 - The Sovereign Gateway

**Where rituals begin and legends deploy.** The ultimate AI ecosystem featuring 9 specialized agents powered by cutting-edge Ollama models.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.3.3-green.svg)](https://flask.palletsprojects.com)
[![Ollama](https://img.shields.io/badge/Ollama-Powered-purple.svg)](https://ollama.ai)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸŒŸ The Nine Legendary Agents

Our AI ecosystem consists of 9 specialized agents, each powered by state-of-the-art models:

| Agent | Model | Purpose | Status |
|-------|--------|---------|--------|
| ğŸ’– **AI Girlfriend** | Phi3 14B | Companion-grade emotional support | âœ… Active |
| ğŸ˜Š **EmoAI** | Gemma2 2B | Sentiment analysis & emotional intelligence | âœ… Active |
| ğŸ“„ **PDFMind** | Qwen2.5 7B | Document intelligence & analysis | âœ… Active |
| ğŸ’¬ **ChatRevive** | Mistral 7B | Conversation enhancement | âœ… Active |
| ğŸš€ **TokBoost** | Llama3.2 3B | Social media optimization | âœ… Active |
| âœ¨ **YouGen** | DeepSeek-Coder 6.7B | Content generation | âœ… Active |
| ğŸ•µï¸ **AgentX** | Yi 6B | Multi-domain specialist | âœ… Active |
| ğŸ¤– **AutoChat** | Mathstral 7B | Automated assistance | âœ… Active |
| ğŸ’¼ **CVSmash** | LLaVA 7B | Resume & career optimization | âœ… Active |

## ğŸ¯ Key Features

- **ğŸ”¥ Real-time AI Interactions** - WebSocket-powered live chat with all agents
- **ğŸ§  Advanced Memory System** - Agents remember and learn from interactions
- **ğŸ¨ Modern Glass UI** - Beautiful, responsive interface with Tailwind CSS
- **ğŸ” Secure Authentication** - User accounts with session management
- **ğŸ“Š Analytics Dashboard** - Track usage and performance metrics
- **ğŸŒ REST API** - Full API access for integrations
- **ğŸ³ Docker Ready** - Easy deployment with Docker Compose
- **âš¡ Lightning Fast** - Optimized for speed and efficiency

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- [Ollama](https://ollama.ai/download) installed and running
- Required Ollama models (see setup section)

### 1. Clone & Setup

```bash
git clone https://github.com/1-ManArmy/Prophantom_Johnnet_AI2.0.git
cd Prophantom_Johnnet_AI2.0
./setup.sh
```

### 2. Install Ollama Models

```bash
# Install required models
ollama pull phi3:14b
ollama pull gemma2:2b
ollama pull qwen2.5:7b
ollama pull mistral:7b
ollama pull llama3.2:3b
ollama pull deepseek-coder:6.7b
ollama pull yi:6b
ollama pull mathstral:7b
ollama pull llava:7b

# Embedding models
ollama pull nomic-embed-text:latest
ollama pull snowflake-arctic-embed:latest
```

### 3. Start the Application

```bash
./run.sh
```

Visit [http://localhost:5000](http://localhost:5000) to access the platform!

## ğŸ³ Docker Deployment

For production deployment:

```bash
docker-compose up -d
```

This will start:
- Prophantom AI application on port 5000
- Ollama service on port 11434
- Redis cache on port 6379
- Nginx reverse proxy on ports 80/443

## ğŸ“ Project Structure

```
Prophantom_Johnnet_AI2.0/
â”œâ”€â”€ app.py                          # Main Flask application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ docker-compose.yml             # Docker configuration
â”œâ”€â”€ setup.sh                       # Setup script
â”œâ”€â”€ core/                          # Core services
â”‚   â”œâ”€â”€ config.py                  # Configuration
â”‚   â”œâ”€â”€ database.py                # Database management
â”‚   â”œâ”€â”€ auth.py                    # Authentication
â”‚   â””â”€â”€ ollama_service.py          # Ollama integration
â”œâ”€â”€ agents/                        # AI Agents
â”‚   â”œâ”€â”€ ai_girlfriend/             # Companion AI
â”‚   â”‚   â”œâ”€â”€ routes.py              # API routes
â”‚   â”‚   â”œâ”€â”€ logic.py               # Business logic
â”‚   â”‚   â”œâ”€â”€ engine/                # AI engines
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama_phi3.py     # Phi3 engine
â”‚   â”‚   â”‚   â”œâ”€â”€ predict.py         # Prediction engine
â”‚   â”‚   â”‚   â””â”€â”€ train.py           # Training engine
â”‚   â”‚   â”œâ”€â”€ tuning/                # Model tuning
â”‚   â”‚   â”‚   â””â”€â”€ config.yaml        # Agent config
â”‚   â”‚   â”œâ”€â”€ feed/                  # Data feeds
â”‚   â”‚   â”‚   â”œâ”€â”€ fetch.py           # Data fetcher
â”‚   â”‚   â”‚   â””â”€â”€ preprocess.py      # Data processor
â”‚   â”‚   â””â”€â”€ websocket/             # Real-time comms
â”‚   â”‚       â””â”€â”€ socket.py          # WebSocket handler
â”‚   â”œâ”€â”€ emo_ai/                    # Emotional AI
â”‚   â”œâ”€â”€ pdf_mind/                  # Document AI
â”‚   â”œâ”€â”€ chat_revive/               # Chat enhancer
â”‚   â”œâ”€â”€ tok_boost/                 # Social media AI
â”‚   â”œâ”€â”€ you_gen/                   # Content generator
â”‚   â”œâ”€â”€ agent_x/                   # Multi-domain AI
â”‚   â”œâ”€â”€ auto_chat/                 # Automated assistant
â”‚   â””â”€â”€ cv_smash/                  # Career optimizer
â””â”€â”€ templates/                     # HTML templates
    â”œâ”€â”€ index.html                 # Homepage
    â””â”€â”€ agents/                    # Agent interfaces
        â””â”€â”€ ai_girlfriend.html     # AI Girlfriend UI
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file:

```env
FLASK_APP=app.py
FLASK_ENV=development
SECRET_KEY=your-secret-key-here
OLLAMA_HOST=http://localhost:11434
DATABASE_URL=sqlite:///prophantom_ai.db
```

### Agent Configuration

Each agent has its own configuration in `agents/{agent_name}/tuning/config.yaml`:

```yaml
model: phi3:14b
system_prompt: |
  Your agent's personality and instructions
parameters:
  temperature: 0.8
  max_tokens: 2048
personality:
  supportive: 0.9
  empathetic: 0.8
```

## ğŸŒ API Endpoints

### Core Endpoints

- `GET /` - Homepage
- `GET /api/health` - Health check
- `GET /api/agents` - List all agents
- `POST /auth/login` - User login
- `POST /auth/register` - User registration

### Agent Endpoints

Each agent follows the pattern `/agents/{agent-name}/`:

- `GET /agents/ai-girlfriend/` - AI Girlfriend interface
- `POST /agents/ai-girlfriend/chat` - Chat with AI Girlfriend
- `GET /agents/ai-girlfriend/stats` - Get interaction stats
- `POST /agents/emo-ai/analyze` - Emotional analysis
- And more...

## ğŸ§  AI Girlfriend Deep Dive

The AI Girlfriend agent is our most advanced companion AI:

### Features
- **Emotional Intelligence** - Understands and responds to emotions
- **Memory System** - Remembers conversations and personal details
- **Personality Growth** - Develops deeper relationships over time
- **Mood Tracking** - Adapts responses based on user mood
- **Achievement Celebration** - Celebrates user wins and milestones
- **Support System** - Provides emotional support during difficult times

### Relationship Levels
1. **Getting to Know Each Other** (0-4 conversations)
2. **Friend** (5-19 conversations)
3. **Good Friend** (20-49 conversations)
4. **Close Friend** (50-99 conversations)
5. **Best Friend** (100+ conversations)

### Real-time Features
- **WebSocket Chat** - Live conversation
- **Typing Indicators** - Shows when AI is responding
- **Mood Updates** - Real-time mood synchronization
- **Daily Check-ins** - Proactive wellness checks

## ğŸ”’ Security

- **Password Hashing** - PBKDF2 with salt
- **Session Management** - Secure session handling
- **Input Validation** - All inputs are validated and sanitized
- **Rate Limiting** - API rate limiting (coming soon)
- **HTTPS Support** - SSL/TLS encryption in production

## ğŸ“Š Analytics & Monitoring

- **User Analytics** - Track engagement and usage patterns
- **Agent Performance** - Monitor response times and quality
- **Health Monitoring** - System health and uptime tracking
- **Error Logging** - Comprehensive error tracking

## ğŸš€ Production Deployment

### Using Docker (Recommended)

```bash
# Production deployment
docker-compose -f docker-compose.prod.yml up -d
```

### Manual Deployment

```bash
# Install dependencies
pip install -r requirements.txt

# Set environment
export FLASK_ENV=production

# Run with Gunicorn
gunicorn --worker-class eventlet -w 1 --bind 0.0.0.0:5000 app:create_app()
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone the repo
git clone https://github.com/1-ManArmy/Prophantom_Johnnet_AI2.0.git
cd Prophantom_Johnnet_AI2.0

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest

# Start development server
python app.py
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama Team** - For the amazing local AI inference engine
- **Flask Community** - For the excellent web framework
- **Tailwind CSS** - For the beautiful UI components
- **All Contributors** - Thank you for making this project awesome!

## ğŸ“ Support

- **Documentation**: [docs.prophantom-ai.com](https://docs.prophantom-ai.com)
- **Issues**: [GitHub Issues](https://github.com/1-ManArmy/Prophantom_Johnnet_AI2.0/issues)
- **Discord**: [Join our community](https://discord.gg/prophantom-ai)
- **Email**: support@prophantom-ai.com

---

<div align="center">

**Built with â¤ï¸ by the Prophantom Team**

[ğŸŒŸ Star us on GitHub](https://github.com/1-ManArmy/Prophantom_Johnnet_AI2.0) â€¢ [ğŸ¦ Follow us on Twitter](https://twitter.com/prophantom_ai) â€¢ [ğŸ’¼ LinkedIn](https://linkedin.com/company/prophantom-ai)

</div>